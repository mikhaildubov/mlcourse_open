{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1** В зале суда есть 5 присяжных, каждый из них по отдельности с вероятностью 70% может правильно определить виновен подсудимый или нет. С какой вероятностью они все вместе вынесут правильный вердикт, если решение принимается большинством голосов?\n",
    "- 70.00%\n",
    "- 83.20%\n",
    "- 83.70%\n",
    "- 87.50%\n",
    "\n",
    "Решение:\n",
    "поскольку большинство голосов – 3, тогда наше m = 3, N = 5, p = 0.7. Подставляем в формулу из статьи $$ \\large \\mu = \\sum_{i=3}^{5}C_5^i0.7^i(1-0.7)^{5-i} $$\n",
    "После подставления и проделывания всех операций получим ответ 83.70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "# отключим предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Сделаем функцию, которая будет заменять NaN значения на медиану в каждом столбце таблицы \n",
    "def delete_nan(table):\n",
    "    for col in table.columns:\n",
    "        table[col]= table[col].fillna(table[col].median())\n",
    "    return table   \n",
    "\n",
    "## Считываем данные\n",
    "data = pd.read_csv('credit_scoring_train.csv', sep =';')\n",
    "\n",
    "independent_columns_names = data.columns.values\n",
    "independent_columns_names = [x for x in data if x != 'SeriousDlqin2yrs']\n",
    "\n",
    "table =delete_nan(data)\n",
    "\n",
    "X =table[independent_columns_names]\n",
    "y = table['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бутстрэп"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.** Сделайте интервальную оценку среднего возраста (age) для клиентов, которые просрочили выплату кредита, с 90% \"уверенностью\". (используйте пример из статьи. Поставьте np.random.seed(0) как это сделано в статье)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean interval [ 45.71379414  46.12700479]\n"
     ]
    }
   ],
   "source": [
    "def get_bootstrap_samples(data, n_samples):\n",
    "    # функция для генерации подвыборок с помощью бутстрэпа\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples\n",
    "def stat_intervals(stat, alpha):\n",
    "    # функция для интервальной оценки\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries\n",
    "\n",
    "# сохранение в отдельные numpy массивы данных по просрочке\n",
    "churn = data[data['SeriousDlqin2yrs'] == 1]['age'].values\n",
    "\n",
    "# ставим seed для воспроизводимости результатов\n",
    "np.random.seed(0)\n",
    "\n",
    "# генерируем выборки с помощью бутстрэра и сразу считаем по каждой из них среднее\n",
    "churn_mean_scores = [np.mean(sample) \n",
    "                       for sample in get_bootstrap_samples(churn, 1000)]\n",
    "\n",
    "#  выводим интервальную оценку среднего\n",
    "print(\"Mean interval\",  stat_intervals(churn_mean_scores, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "lr = LogisticRegression(random_state=5, class_weight= 'balanced')\n",
    "parameters = {'C': (0.0001, 0.001, 0.01, 0.1, 1, 10)}\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Задание 3.**\n",
    "Сделайте GridSearch с метрикой \"roc-auc\" по параметру C. Какое оптимальное значение параметра С?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=5,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(lr, parameters, n_jobs=-1, scoring ='roc_auc', cv=skf)\n",
    "grid_search = grid_search.fit(X, y)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.** \n",
    "Можно ли считать лучшую модель устойчивой? (модель считаем устойчивой, если стандартное отклонение на валидации меньше 0.5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0037606335564454828"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_['std_test_score'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79602038989281942"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение влияния признаков\n",
    "\n",
    "**Задание 5.** Определите самый важный признак. Важность признака определяется абсолютным значением его коэффициента. Так же нужно нормализировать все признаки, что бы можно их было корректно сравнить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age     -0.416303678767\n",
      "NumberOfTime30-59DaysPastDueNotWorse     0.7240043159\n",
      "DebtRatio     -0.0240818648119\n",
      "NumberOfTimes90DaysLate     0.517672915413\n",
      "NumberOfTime60-89DaysPastDueNotWorse     0.194732165768\n",
      "MonthlyIncome     -0.162863529686\n",
      "NumberOfDependents     0.101326025081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "lr = LogisticRegression(C=0.001,random_state=5, class_weight= 'balanced')\n",
    "scal = StandardScaler()\n",
    "lr.fit(scal.fit_transform(X), y)\n",
    "for f, c in zip(independent_columns_names, lr.coef_[0]):\n",
    "    print(f,c,sep=\"     \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый важный признак – NumberOfTime30-59DaysPastDueNotWorse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.** Посчитайте долю влияния `DebtRatio` на предсказание. (Реализуйте функцию [softmax](https://en.wikipedia.org/wiki/Softmax_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.114205367199\n"
     ]
    }
   ],
   "source": [
    "print((np.exp(lr.coef_[0]) / np.sum(np.exp(lr.coef_[0])))[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7.** \n",
    "Давайте посмотрим как можно интерпретировать влияние наших признаков. Для этого заного оценим логистическую регрессию в абсолютных величинах. После этого посчитайте во сколько раз увеличатся шансы, что клиент не выплатит кредит, если увеличить возраст на 20 лет при всех остальных равных значениях признаков. (теоретический расчет можно посмотреть [здесь](https://www.unm.edu/~schrader/biostat/bio2/Spr06/lec11.pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age     -0.0181852818846\n",
      "NumberOfTime30-59DaysPastDueNotWorse     0.482349233865\n",
      "DebtRatio     -1.07983115273e-05\n",
      "NumberOfTimes90DaysLate     0.430314155406\n",
      "NumberOfTime60-89DaysPastDueNotWorse     0.0659578713554\n",
      "MonthlyIncome     -1.14476586003e-05\n",
      "NumberOfDependents     0.11535624898\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=0.001,random_state=5, class_weight= 'balanced')\n",
    "lr.fit(X, y)\n",
    "for f, c in zip(independent_columns_names, lr.coef_[0]):\n",
    "    print(f,c,sep=\"     \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6950957746271984"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(lr.coef_[0][0]*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\exp^{\\beta\\delta}$ – во столько раз больше шансы, что клиент не выплатит кредит. Где $\\delta$ – на сколько делаем прирост. Например, если увеличить возраст на 20 лет, то шансы, что человек не выплатит в кредит увеличатся в 0.69."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Инициализируем случайный лес с 100 деревьями и сбалансированными классами \n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42, oob_score=True, class_weight='balanced')\n",
    "\n",
    "## Будем искать лучшие параметры среди следующего набора\n",
    "parameters = {'max_features': [1, 2, 4], 'min_samples_leaf': [3, 5, 7, 9], 'max_depth': [5,10,15]}\n",
    "\n",
    "## Делаем опять же стрэтифайд k-fold валидацию. Инициализация которой должна у вас продолжать храниться в skf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 8.** На сколько точность лучшей модели случайного леса выше точности логистической регрессии на валидации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0396110583184\n"
     ]
    }
   ],
   "source": [
    "# Ответ 5\n",
    "rf_grid_search = GridSearchCV(rf, parameters, n_jobs=-1, scoring ='roc_auc', cv=skf)\n",
    "rf_grid_search = rf_grid_search.fit(X, y)\n",
    "print(rf_grid_search.best_score_ - grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 9.** Определите какой признак имеет самое слабое влияние."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NumberOfDependents'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_columns_names[argmin(rf_grid_search.best_estimator_.feature_importances_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание 10.** Какое наиболее существенное примущество логистической регрессии перед случайным лесом для нашей бизнес-задачи?\n",
    "\n",
    "- меньше тратится времени для тренировки модели;\n",
    "- меньше параметров для перебора;\n",
    "- интепретируемость признаков;\n",
    "- линейные свойства алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге мы получили, что алгоритм случайно леса лучше сработал для нашей задачи скоринга. Точность случайного леса почти на 4% выше. Причинами такого результата стали – небольшое количество признаков и свойства случайного леса, как композиции.\n",
    "\n",
    "Но преимущество логистической регрессии в том, что мы можем проинтерпретировать влияние коэффициентов на результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бэггинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "parameters = {'max_features': [2, 3, 4], 'max_samples': [0.5, 0.7, 0.9], \"base_estimator__C\": [0.0001, 0.001, 0.01, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 11.** Следующая задача обучить бэггинг классификатор. В качестве базовых классификаторов возьмите 100 логистических регрессий и на этот раз используйте не GridSearchCV, а RandomizedSearchCV. Так как перебирать все 54 варианта комбинаций долго, то поставьте максимальное число итераций 20 для RandomizedSearchCV. Так же не забудьте передать параметр валидации cv и random_state=1. Какая лучшая точность получилась?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bg = BaggingClassifier(LogisticRegression(class_weight= 'balanced'),n_estimators=100, n_jobs=-1, random_state=42)\n",
    "r_grid_search = RandomizedSearchCV(bg, parameters, n_jobs=-1, scoring ='roc_auc', cv=skf, n_iter=20, random_state=1)\n",
    "r_grid_search = r_grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80746778722957357"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Задача 12.** Дайте интерпретацию лучших параметров для бэггинга. Почему именно такие значения оказались лучшими?\n",
    "\n",
    "- для бэггинга важно использовать как можно меньше признаков\n",
    "- бэггинг лучше работает на небольших выборках\n",
    "- меньше корреляция между одиночными моделями\n",
    "- чем больше признаков, тем меньше теряется информации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преимущество случайного леса в том, что деревья в композиции не коррелируют между собой и это дает максимальную пользу. Аналогично и для бэггинга с логистической регрессией, чем слабее коррелируют между собой одиночные модели, тем выше точность. Поскольку в логистической регрессии практически нет случайности, то мы должны менять наборы признаков и объектов для достижении максимальной декоррелированости наших моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
